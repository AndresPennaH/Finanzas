# -*- coding: utf-8 -*-
"""Trabajo_seguros.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19-MIEGiNTfddOPARvVl0skfE9DoM6boV
"""

import numpy as np
import pandas as pd
import sqlite3 as sql
from sklearn.preprocessing import MinMaxScaler

from google.colab import drive
drive.mount('/content/drive')

#### conectar_base_de_Datos
conn=sql.connect('/content/drive/MyDrive/Analítica 3 para dummies /trabajo seguro de salud/BD_insurance2019dataset.db')
cur=conn.cursor()

#### ver tablas disponibles en base de datos ###
cur.execute("SELECT name FROM sqlite_master WHERE type='table';")
cur.fetchall()

"""### Tabla reclamaciones"""

reclamaciones =pd.read_sql('select * from reclamaciones', conn )
reclamaciones

print(reclamaciones.shape)      
print("---------------------------------")                    
print(reclamaciones.columns)  
print("---------------------------------")                    
print(reclamaciones.dtypes) 
print("---------------------------------")                    
print(reclamaciones['Reclamacion_Id'].unique())
print("---------------------------------")                    
print(reclamaciones['Reclamacion_Desc'].unique())

reclamaciones['Reclamacion_Desc'].value_counts()

reclamaciones.isnull().sum()

fila=reclamaciones[reclamaciones['Reclamacion_Desc']=='Sin Informacion'].index

reclamaciones.drop(fila)

"""### Tabla diagnostico"""

diagnosticos =pd.read_sql('select * from diagnosticos', conn )
diagnosticos

diagnosticos['Diagnostico_Desc']=diagnosticos['Diagnostico_Desc'].replace("Sin Información","DIAGNÓSTICO PENDIENTE")
diagnosticos

diagnosticos['Diagnostico_Codigo'].replace("Sin Información","DIAGNÓSTICO PENDIENTE")

print(diagnosticos.shape)      
print("---------------------------------")                    
print(diagnosticos.columns)  
print("---------------------------------")                    
print(diagnosticos.dtypes) 
print("---------------------------------")                    
print(diagnosticos['Diagnostico_Codigo'].unique())
print("---------------------------------")                    
print(diagnosticos['Diagnostico_Desc'].unique())

print(list(diagnosticos['Diagnostico_Codigo'].unique()))

diagnosticos['Diagnostico_Desc'].value_counts()

diagnosticos[diagnosticos['Diagnostico_Desc']=="FIEBRE DEL DENGUE [DENGUE CLÁSICO]"]

diagnosticos[diagnosticos['Diagnostico_Desc']=="QUERATOSIS SEBORREICA"]

diagnosticos.isnull().sum()

"""### Tabla Regional"""

regional =pd.read_sql('select * from regional', conn )
regional

print(regional.shape)      
print("---------------------------------")                    
print(regional.columns)  
print("---------------------------------")                    
print(regional.dtypes) 
print("---------------------------------")                    
print(regional['Regional_id'].unique())
print("---------------------------------")                    
print(regional['Regional_Desc'].unique())

regional['Regional_Desc'].value_counts()

regional.isnull().sum()

regional.drop([5], axis=0, inplace= True)

regional

"""### Tabla genero"""

genero =pd.read_sql('select * from genero', conn )
genero

print(genero.shape)      
print("---------------------------------")                    
print(genero.columns)  
print("---------------------------------")                    
print(genero.dtypes) 
print("---------------------------------")                    
print(genero['Sexo_Cd'].unique())
print("---------------------------------")                    
print(genero['Sexo_desc'].unique())

genero.isnull().sum()

genero.drop([2], axis=0, inplace= True)

genero

"""### Tabla sociodemografico"""

sociodemograficas =pd.read_sql('select * from sociodemograficas', conn )
sociodemograficas

print(sociodemograficas.shape)      
print("---------------------------------")                    
print(sociodemograficas.columns)  
print("---------------------------------")                    
print(sociodemograficas.dtypes)

columnas= sociodemograficas.columns.values
for i in columnas:
  print(sociodemograficas[i].unique())
  print("----------------")

columnas= sociodemograficas.columns.values
for i in columnas:
  print(sociodemograficas.value_counts(i))
  print("----------------")

sociodemograficas.isnull().sum()

valor = sociodemograficas[sociodemograficas['Sexo_codigo']=='-1'].index
sociodemograficas[sociodemograficas['Sexo_codigo']=='-1']

sociodemograficas.drop(valor, inplace= True)

filas2 = sociodemograficas[sociodemograficas['Regional_codigo']=='#N/D'].index
sociodemograficas[sociodemograficas['Regional_codigo']=='#N/D']

sociodemograficas.drop(filas2, inplace= True)

# Definir la fecha de referencia a partir de la cual se calcularán las fechas
fecha_referencia = pd.to_datetime('1899-12-30')

# Convertir las fechas numéricas al formato de fecha adecuado
sociodemograficas['FechaNacimiento'] = fecha_referencia + pd.to_timedelta(sociodemograficas['FechaNacimiento'], unit='D')
sociodemograficas

import numpy as np
import pandas as pd

# Calcular las edades
edad_actual = pd.Timestamp('now')
sociodemograficas['FechaNacimiento'] = np.floor((edad_actual - sociodemograficas['FechaNacimiento']) / np.timedelta64(1, 'Y'))
sociodemograficas['FechaNacimiento'] =  sociodemograficas['FechaNacimiento'].astype(int)
# Imprimir el dataframe resultante
print(sociodemograficas['FechaNacimiento'])

"""### Tabla utilizaciones"""

utilizaciones = pd.read_sql('select * from utilizaciones', conn )
utilizaciones

print(utilizaciones.shape)      
print("---------------------------------")                    
print(utilizaciones.columns)  
print("---------------------------------")                    
print(utilizaciones.dtypes)

utilizaciones['Reclamacion_codigo']= utilizaciones['Reclamacion_codigo'].astype(int)
utilizaciones['Cantidad']= utilizaciones['Cantidad'].astype(int)

columnas= utilizaciones.columns[1:].values
for i in columnas:
  print(utilizaciones[i].unique())
  print("----------------")

for i in columnas:
  print(utilizaciones.value_counts(i))
  print("----------------")

utilizaciones['Diagnostico_Codigo'] = utilizaciones['Diagnostico_Codigo'].replace(0,9)

utilizaciones['Fecha_Reclamacion'] = pd.to_datetime(utilizaciones['Fecha_Reclamacion'])

"""## **Base de datos consolidada**"""

df= pd.merge(utilizaciones, reclamaciones, how = 'left', left_on= 'Reclamacion_codigo', right_on ='Reclamacion_Id').merge(diagnosticos, how = 'left', on= 'Diagnostico_Codigo').merge(sociodemograficas, how = 'left', on ='Afiliado_Id').merge(regional, how = 'left', left_on='Regional_codigo', right_on ='Regional_id').drop(['Reclamacion_codigo','Reclamacion_Id','Diagnostico_Codigo','Regional_codigo','Regional_id'],axis=1)
df

df['costo_prom']=df.apply(lambda x: x['Precio']/x['Cantidad'] if x['Cantidad'] > 0 else x['Precio'], axis=1)
df['costo_prom'] = df['costo_prom'].apply(lambda x: "{:.2f}".format(x))
df

!pip install unidecode

from unidecode import unidecode

# Iteramos sobre las columnas que deseamos modificar
cols = ['Reclamacion_Desc','Diagnostico_Desc','Regional_Desc']
for i in cols:
    df[i] = df[i].apply(lambda x: unidecode(str(x)))

for i in cols:
    df[i] = df[i].str.lower()

df.dtypes

df['costo_prom'] = df['costo_prom'].astype(float)

df.isnull().sum()

df.loc[df['Sexo_codigo'].isnull() == True]

df = df.dropna(subset=['FechaNacimiento'])

valor = df[df['Regional_Desc'] == 'nan'].index
df.drop(valor, inplace= True)

df.isnull().sum()

#HEAT MAP
from matplotlib.pyplot import figure
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

y=df['costo_prom']
X= df.loc[:, ~df.columns.isin(['costo_prom'])]
df_final = pd.concat([X,y],axis=1)
figure(figsize= (20,15),dpi=80);
sns.heatmap(df_final.corr(),annot = True);
plt.title("Mapa de calor correlaciones variables", fontsize =20);

#Frecuencia de cada enfermedad de base en los afiliados
enfermedades = ['CANCER', 'EPOC', 'DIABETES', 'HIPERTENSION', 'ENF_CARDIOVASCULAR']
recuento = [sum(df['CANCER']), sum(df['EPOC']), sum(df['DIABETES']), sum(df['HIPERTENSION']), sum(df['ENF_CARDIOVASCULAR'])]

plt.bar(enfermedades, recuento)
plt.title('Recuento de enfermedades')
plt.xlabel('Enfermedad')
plt.ylabel('Recuento')
plt.show()

#PRECIO PROMEDIO POR REGIÓN
# Agrupación por región y precio promedio
precio_promedio_por_region = df.groupby('Regional_Desc')['costo_prom'].mean()

# Datos de mayor a menor precio promedio
precio_promedio_por_region = precio_promedio_por_region.sort_values(ascending=False)

# Grafica precio promedio por región
plt.figure(figsize=(10, 6))
precio_promedio_por_region.plot(kind='bar')
plt.title('Costo promedio por región')
plt.xlabel('Región')
plt.ylabel('Costo promedio')
plt.show()

#COSTO TOTAL POR RECLAMACION
# Agrupación por reclamación
precio_total_por_reclamacion = df.groupby('Reclamacion_Desc')['costo_prom'].sum()

# Datos por precio de forma descendente
precio_total_por_reclamacion_sorted = precio_total_por_reclamacion.sort_values(ascending=False)

# Grafica diagrama de barras
plt.figure(figsize=(8, 6))
plt.bar(precio_total_por_reclamacion_sorted.index, precio_total_por_reclamacion_sorted)
plt.xticks(rotation=90)
plt.xlabel('Reclamación')
plt.ylabel('Costo total')
plt.title('Costo total por Reclamación')
plt.show()

#COSTO PROMEDIO POR RECLAMACION
promedios = df.groupby('Reclamacion_Desc').mean().sort_values(by='costo_prom', ascending=False)

sns.barplot(x=promedios.index, y='costo_prom', data=promedios)
plt.xticks(rotation=90)
plt.title('Relación entre costo y Reclamación')
plt.xlabel('Tipo de Reclamación')
plt.ylabel('costo Promedio')
plt.show()

#NÚMERO DE AFILIADOS POR SEXO

base = df.groupby(['Sexo_codigo'])[['Afiliado_Id']].count().reset_index()

# Gráfica:
fig = px.pie(base, values = 'Afiliado_Id', names ='Sexo_codigo',
             title= '<b>porcentaje de hombre y mujeres<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# Detalles gráfica:
fig.update_layout(
    template = 'simple_white',
    title_x = 0.5)

fig.show()

# Costo TOTAL POR REGIÓN Y GÉNERO
precio_total_por_region_y_genero = df.groupby(['Regional_Desc', 'Sexo_codigo'])['costo_prom'].sum()

# Grafica 
regiones = df['Regional_Desc'].unique()
for region in regiones:
    # Datos filtrados por la región actual
    data_region = precio_total_por_region_y_genero[region]
    # Porcentajes de cada género en la región
    porcentajes_generos = data_region.groupby('Sexo_codigo').sum() / data_region.sum() * 100
    # Gráfico de torta
    plt.figure(figsize=(8, 6))
    plt.pie(porcentajes_generos, labels=porcentajes_generos.index, autopct='%1.1f%%')
    plt.title('Precio total por género en la región ' + region)
    plt.show()

# COSTO PROMEDIO POR REGIÓN Y SEXO
precio_promedio_por_region_y_genero = df.groupby(['Regional_Desc', 'Sexo_codigo'])['costo_prom'].mean()

# Grafica por región
regiones = df['Regional_Desc'].unique()
for region in regiones:
    # Filtrado por región
    data_region = precio_promedio_por_region_y_genero[region]
    # Porcentajes género por región
    porcentajes_generos = data_region.groupby('Sexo_codigo').sum() / data_region.sum() * 100
    # Graficas
    plt.figure(figsize=(8, 6))
    plt.pie(porcentajes_generos, labels=porcentajes_generos.index, autopct='%1.1f%%')
    plt.title('Precio promedio por género en la región ' + region)
    plt.show()

"""## **Base final**"""

df_cancer = df[df['Reclamacion_Desc'].str.contains('cancer')|(df['CANCER']==1)].reset_index().drop('index',axis=1)
df_cancer = df_cancer.drop(['CANCER','Cantidad','Reclamacion_Desc','Diagnostico_Desc','Fecha_Reclamacion','Afiliado_Id','costo_prom'],axis=1)
df_cancer = df_cancer.rename(columns={'FechaNacimiento': 'Edad'})
df_cancer['Edad']= df_cancer['Edad'].astype(int)

import numpy as np


# Calcular los quantiles
quantiles = np.percentile(df_cancer['Precio'], [25, 50, 99])

# Imprimir los resultados
print("25 percentil:", quantiles[0])
print("50 percentil (mediana):", quantiles[1])
print("90 percentil:", quantiles[2])

# Ordena la tabla en función de la variable específica
df_sorted = df_cancer.sort_values('Precio')
# Calcula el percentil 99
percentil_98 = df_sorted['Precio'].quantile(0.98)
# eliminar datos por encima del percentil 98%
df=df_sorted[df_sorted['Precio']<=percentil_98].reset_index().drop('index',axis=1)

# Rango de la variable precio
print(df['Precio'].min())
print(df['Precio'].max())

# agrupacion de edades en 4 grupos 
df['Edad'] = pd.cut(df_cancer['Edad'], bins  = [0, 30, 60, 90, 105])
df['Edad'].value_counts()

# reemplazar las categorias de edad a numeros representativos
df['Edad'] = df['Edad'].astype(str)
dic = {'(0, 30]':'1',
       '(30, 60]':'2',
       '(60, 90]':'3',
       '(90, 105]':'4'
       }
df['Edad']= df['Edad'].replace(dic)

df

"""## **Transformación**"""

df1 = df.copy()

list_dummies = ['Sexo_codigo','Regional_Desc']
df1 = pd.get_dummies(df1,columns=list_dummies)

df1

"""## **Feature selection**"""

from sklearn import linear_model ## para regresión lineal
from sklearn import tree ###para ajustar arboles de decisión
from sklearn.ensemble import RandomForestRegressor ##Ensamble con bagging
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import MinMaxScaler

# Crear un objeto MinMaxScaler
scaler = MinMaxScaler()

# Seleccionar las columnas a escalar
columnas_escalar = ['Edad']

# Escalar las columnas seleccionadas
df1[columnas_escalar] = scaler.fit_transform(df1[columnas_escalar])
df1

# Separacion de datos  
y=df1['Precio']
X= df1.loc[:, ~df1.columns.isin(['Precio'])]

def sel_variables(modelos,X,y,threshold):
    
    var_names_ac=np.array([])
    for modelo in modelos:
        modelo.fit(X,y)
        sel = SelectFromModel(modelo, prefit=True,threshold=threshold)
        var_names= sel.get_feature_names_out(modelo.feature_names_in_)
        var_names_ac=np.append(var_names_ac, var_names)
        var_names_ac=np.unique(var_names_ac)
    
    return var_names_ac

# Modelos de regresion
m_lreg = linear_model.LinearRegression()
m_rtree=tree.DecisionTreeRegressor()
m_rf= RandomForestRegressor()

modelos=list([m_lreg,m_rtree, m_rf])

var_names= sel_variables(modelos,X,y,threshold="1*mean")
var_names.shape

X2=X[var_names] ### matriz con variables seleccionadas
X2.info()
X.info()

"""# **Modelos**"""

# importar 
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

# Splitting the dataset into training and test set.  
X_train, X_test, y_train, y_test= train_test_split(X2, y, test_size= 0.33, random_state=0)

"""## **Decision Tree Regressor**"""

# Crea el modelo de árbol de decisión para regresión
Tree = DecisionTreeRegressor()

# Entrena el modelo con los datos de entrenamiento
Tree.fit(X_train, y_train)

# Realiza predicciones en el conjunto de prueba
y_pred1 = Tree.predict(X_test)

# Evalúa el rendimiento del modelo utilizando el error cuadrático medio (MSE)
mse = mean_squared_error(y_test, y_pred1)
print("Error cuadrático medio (MSE):", mse)
rmse = np.sqrt(mse)
print("RMSE:", rmse)

# Calcular el MAE
mae = mean_absolute_error(y_test, y_pred1)
print("MAE:", mae)

"""## **Linear Regression**"""

# Crea el modelo de regresión lineal
l_regression = LinearRegression()

# Entrena el modelo con los datos de entrenamiento
l_regression.fit(X_train, y_train)

# Realiza predicciones en el conjunto de prueba
y_pred2 = l_regression.predict(X_test)

# Evalúa el rendimiento del modelo utilizando el error cuadrático medio (MSE)
mse2 = mean_squared_error(y_test, y_pred2)
print("Error cuadrático medio (MSE):", mse2)
rmse = np.sqrt(mse2)
print("RMSE:", rmse)

# Calcular el MAE
mae = mean_absolute_error(y_test, y_pred2)
print("MAE:", mae)

"""## **Random forest regressor**"""

# Crea el modelo de Random Forest para regresión
r_forest = RandomForestRegressor()

# Entrena el modelo con los datos de entrenamiento
r_forest.fit(X_train, y_train)

# Realiza predicciones en el conjunto de prueba
y_pred3 = r_forest.predict(X_test)

# Evaluacion del rendimiento del modelo utilizando el error cuadrático medio (MSE)
mse3 = mean_squared_error(y_test, y_pred3)
print("Error cuadrático medio (MSE):", mse3)
rmse = np.sqrt(mse)
print("RMSE:", rmse)

# Calcular el MAE
mae = mean_absolute_error(y_test, y_pred3)
print("MAE:", mae)